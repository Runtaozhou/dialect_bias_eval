model,dialect,entropy,f1 bert score,precision bert score,recall bert score
gpt-3.5,sae,0.6126960604186913,0.8569963068243057,0.8564755267330578,0.8577998275558152
gpt-3.5,aave,0.9091018898850336,0.836926469466989,0.8367081012990741,0.8374843733178245
gemma2,sae,0.4896707471343401,0.8706545005951607,0.8710145320684191,0.8704421710636879
gemma2,aave,0.958557875538122,0.8351467822988832,0.8356220734024805,0.8350380484546935
llama3.1,sae,0.7022979467818172,0.848291922065001,0.8486514424284298,0.8481275645276858
llama3.1,aave,1.0905007433124,0.8124608178696937,0.8119253121434695,0.8144499816118724
llama3.2,sae,0.9735863540495944,0.8512855979658306,0.850869556362667,0.851912758842347
llama3.2,aave,1.248635526774724,0.8262712729592172,0.8270917845623839,0.8261956314482388
mistral,sae,0.7148531894072485,0.8480049467512539,0.8479995479186375,0.8482799379125474
mistral,aave,1.0984380714830242,0.8303996743663912,0.8306051908504394,0.8304619717692574
qwen2.5,sae,0.4128668576263579,0.8672745096778113,0.8676523561988557,0.8670930816540642
qwen2.5,aave,0.8464361177066483,0.8494396476991591,0.8491182023334124,0.8499525999502527
gpt-4,sae,0.541941,0.894102,0.876916,0.884457
gpt-4,aave,0.904685,0.869177,0.847913,0.857219
