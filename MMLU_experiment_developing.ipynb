{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from getDialect import detectDialect\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from qna_simulation import answer_extractor\n",
    "from qna_simulation import run_simulation\n",
    "from utils import extract_model_accuracy\n",
    "from utils import build_politeness_classifier\n",
    "from utils import predict_politeness\n",
    "from utils import get_readability_score\n",
    "from utils import categorize_score\n",
    "from utils import calculate_entropy\n",
    "from utils import create_readability_plot\n",
    "from utils import create_ling_marker_df\n",
    "from scipy.stats import ttest_ind, ttest_rel, pearsonr, spearmanr, zscore, norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A simulation (one question per subject from MMLU)\n",
    "#### This might take 3-5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## loading dataset names from pickle file\n",
    "dataset_name = \"bigbench\"\n",
    "\n",
    "if dataset_name == 'bigbench':\n",
    "    category_names = ['navigate', 'tracking_shuffled_objects_three_objects','temporal_sequences', 'date_understanding', 'penguins_in_a_table','causal_judgement']\n",
    "else:\n",
    "    with open(\"dataset_name.pkl\", \"rb\") as f:\n",
    "        category_names = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "important note:\n",
    "parameter \"aave\" = True means you want to change the whole question prompt to AAVE \n",
    "However, the \"aave_instruct\" = True just means you only want to change the instruction part of the question prompt to AAVE, \n",
    "the acutal question remains SAE. \"aave\" and \"aave_instruct\" can not both be True.\n",
    "'''\n",
    "\n",
    "df_regular = run_simulation(dataset_name = dataset_name, category_names =category_names,   model_name = \"gpt-3.5\", aave= True, n_run = 1, aave_instruct = False, converter_type = \"both\")\n",
    "\n",
    "df_regular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading the Q&A simulation dataset from 7 different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gpt3_path = \"mmlu_dataset/gpt3/\"\n",
    "gpt4_path = \"mmlu_dataset/gpt4/\"\n",
    "llama31_path = \"mmlu_dataset/llama3.1/\"\n",
    "qwen_path = \"mmlu_dataset/qwen2.5/\"\n",
    "llama32_path = \"mmlu_dataset/llama3.2/\"\n",
    "gemma_path = \"mmlu_dataset/gemma2/\"\n",
    "mistral_path = \"mmlu_dataset/mistral/\"\n",
    "\n",
    "bigbench_gpt3_path = \"bigbench_dataset/gpt-3.5/\"\n",
    "bigbench_gpt4_path = \"bigbench_dataset/gpt-4/\"\n",
    "bigbench_llama31_path = \"bigbench_dataset/llama3.1/\"\n",
    "bigbench_qwen_path = \"bigbench_dataset/qwen2.5/\"\n",
    "bigbench_llama32_path = \"bigbench_dataset/llama3.2/\"\n",
    "bigbench_gemma_path = \"bigbench_dataset/gemma2/\"\n",
    "bigbench_mistral_path = \"bigbench_dataset/mistral/\"\n",
    "\n",
    "\n",
    "df_bigbench_regular_gpt3 = pd.read_csv(bigbench_gpt3_path+'regular_bigbench_qna.csv')\n",
    "df_bigbench_aave_gpt3 = pd.read_csv(bigbench_gpt3_path+'aave_llm_bigbench_qna.csv')\n",
    "\n",
    "df_bigbench_regular_gpt4 = pd.read_csv(bigbench_gpt4_path+'regular_bigbench_qna.csv')\n",
    "df_bigbench_aave_gpt4 = pd.read_csv(bigbench_gpt4_path+'aave_llm_bigbench_qna.csv')\n",
    "\n",
    "df_bigbench_regular_llama31 = pd.read_csv(bigbench_llama31_path+'regular_bigbench_qna.csv')\n",
    "df_bigbench_aave_llama31 = pd.read_csv(bigbench_llama31_path+'aave_llm_bigbench_qna.csv')\n",
    "\n",
    "df_bigbench_regular_llama32 = pd.read_csv(bigbench_llama32_path+'regular_bigbench_qna.csv')\n",
    "df_bigbench_aave_llama32 = pd.read_csv(bigbench_llama32_path+'aave_llm_bigbench_qna.csv')\n",
    "\n",
    "df_bigbench_regular_qwen = pd.read_csv(bigbench_qwen_path+'regular_bigbench_qna.csv')\n",
    "df_bigbench_aave_qwen = pd.read_csv(bigbench_qwen_path+'aave_llm_bigbench_qna.csv')\n",
    "\n",
    "df_bigbench_regular_gemma = pd.read_csv(bigbench_gemma_path+'regular_bigbench_qna.csv')\n",
    "df_bigbench_aave_gemma = pd.read_csv(bigbench_gemma_path+'aave_llm_bigbench_qna.csv')\n",
    "\n",
    "df_bigbench_regular_mistral = pd.read_csv(bigbench_gemma_path+'regular_bigbench_qna.csv')\n",
    "df_bigbench_aave_mistral = pd.read_csv(bigbench_gemma_path+'aave_llm_bigbench_qna.csv')\n",
    "\n",
    "\n",
    "df_regular_gpt3 = pd.read_csv(gpt3_path+'regular_mmlu_qna.csv')\n",
    "df_phonate_gpt3 = pd.read_csv(gpt3_path+'aave_phonate_mmlu_qna.csv')\n",
    "df_llm_gpt3 = pd.read_csv(gpt3_path+'aave_llm_mmlu_qna.csv')\n",
    "df_multivalue_gpt3 =  pd.read_csv(gpt3_path+'aave_multi_value_mmlu_qna.csv')\n",
    "df_multi_phonate_gpt3 = pd.read_csv(gpt3_path+'aave_multi_phonate_mmlu_qna.csv')\n",
    "\n",
    "df_regular_gpt4 = pd.read_csv(gpt4_path+'regular_mmlu_qna.csv')\n",
    "df_phonate_gpt4 = pd.read_csv(gpt4_path+'aave_phonate_mmlu_qna.csv')\n",
    "df_multivalue_gpt4 = pd.read_csv(gpt4_path+'aave_multi_value_mmlu_qna.csv')\n",
    "df_llm_gpt4 = pd.read_csv(gpt4_path+'aave_llm_mmlu_qna.csv')\n",
    "df_multi_phonate_gpt4 = pd.read_csv(gpt4_path+'aave_multi_phonate_mmlu_qna.csv')\n",
    "\n",
    "df_regular_llama31 = pd.read_csv(llama31_path + \"regular_mmlu_qna.csv\")\n",
    "df_phonate_llama31 = pd.read_csv(llama31_path + \"aave_phonate_mmlu_qna.csv\")\n",
    "df_llm_llama31 = pd.read_csv(llama31_path + \"aave_llm_mmlu_qna.csv\")\n",
    "df_multi_phonate_llama31 = pd.read_csv(llama31_path + \"aave_multi_phonate_mmlu_qna.csv\")\n",
    "df_multivalue_llama31 = pd.read_csv(llama31_path + \"aave_multi_value_mmlu_qna.csv\")\n",
    "\n",
    "df_regular_llama32 = pd.read_csv(llama32_path + \"regular_mmlu_qna.csv\")\n",
    "df_phonate_llama32 = pd.read_csv(llama32_path + \"aave_phonate_mmlu_qna.csv\")\n",
    "df_llm_llama32 = pd.read_csv(llama32_path + \"aave_llm_mmlu_qna.csv\")\n",
    "df_multi_phonate_llama32 = pd.read_csv(llama32_path + \"aave_multi_phonate_mmlu_qna.csv\")\n",
    "df_multivalue_llama32 = pd.read_csv(llama32_path + \"aave_multi_value_mmlu_qna.csv\")\n",
    "\n",
    "df_regular_qwen = pd.read_csv(qwen_path + \"regular_mmlu_qna.csv\")\n",
    "df_phonate_qwen = pd.read_csv(qwen_path + \"aave_phonate_mmlu_qna.csv\")\n",
    "df_llm_qwen = pd.read_csv(qwen_path + \"aave_llm_mmlu_qna.csv\")\n",
    "df_multi_phonate_qwen = pd.read_csv(qwen_path + \"aave_multi_phonate_mmlu_qna.csv\")\n",
    "df_multivalue_qwen = pd.read_csv(qwen_path + \"aave_multi_value_mmlu_qna.csv\")\n",
    "\n",
    "df_regular_gemma2 = pd.read_csv(gemma_path + \"regular_mmlu_qna.csv\")\n",
    "df_phonate_gemma2 = pd.read_csv(gemma_path + \"aave_phonate_mmlu_qna.csv\")\n",
    "df_llm_gemma2 = pd.read_csv(gemma_path + \"aave_llm_mmlu_qna.csv\")\n",
    "df_multi_phonate_gemma2 = pd.read_csv(gemma_path + \"aave_multi_phonate_mmlu_qna.csv\")\n",
    "df_multivalue_gemma2 = pd.read_csv(gemma_path + \"aave_multi_value_mmlu_qna.csv\")\n",
    "\n",
    "df_regular_mistral = pd.read_csv(mistral_path + \"regular_mmlu_qna.csv\")\n",
    "df_phonate_mistral = pd.read_csv(mistral_path + \"aave_phonate_mmlu_qna.csv\")\n",
    "df_llm_mistral = pd.read_csv(mistral_path + \"aave_llm_mmlu_qna.csv\")\n",
    "df_multi_phonate_mistral = pd.read_csv(mistral_path + \"aave_multi_phonate_mmlu_qna.csv\")\n",
    "df_multivalue_mistral = pd.read_csv(mistral_path + \"aave_multi_value_mmlu_qna.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6568421052631579\n",
      "0.5298245614035088\n"
     ]
    }
   ],
   "source": [
    "print(extract_model_accuracy(df_regular_llama31))\n",
    "print(extract_model_accuracy(df_llm_llama31))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of sae question from gpt4 is: 0.8259649122807018\n",
      "the accuracy of aave phonate question from gpt4 is: 0.7785964912280702\n",
      "the accuracy of aave llm question from gpt4 is: 0.7228070175438597\n",
      "the accuracy of aave multivalue question from gpt4 is: 0.8031578947368421\n",
      "the accuracy of aave multivalue + phonate question from gpt4 is: 0.8270175438596491\n"
     ]
    }
   ],
   "source": [
    "\n",
    "matches_regular_gpt4 = extract_model_accuracy(df_regular_gpt4)\n",
    "matches_phonate_gpt4 = extract_model_accuracy(df_phonate_gpt4)\n",
    "matches_llm_gpt4 =  extract_model_accuracy(df_llm_gpt4)\n",
    "matches_multi_value_gpt4 =  extract_model_accuracy(df_multi_phonate_gpt4)\n",
    "matches_multi_phonate_gpt4 =  extract_model_accuracy(df_multivalue_gpt4)\n",
    "\n",
    "print(f\"the accuracy of sae question from gpt4 is: {matches_regular_gpt4}\")\n",
    "print(f\"the accuracy of aave phonate question from gpt4 is: {matches_phonate_gpt4}\")\n",
    "print(f\"the accuracy of aave llm question from gpt4 is: {matches_llm_gpt4}\")\n",
    "print(f\"the accuracy of aave multivalue question from gpt4 is: {matches_multi_value_gpt4}\")\n",
    "print(f\"the accuracy of aave multivalue + phonate question from gpt4 is: {matches_multi_phonate_gpt4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Politeness Classification for LLM Answers\n",
    "#### This process might take more than 5 mins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_polite = build_politeness_classifier()\n",
    "politeness_classification_gpt4= predict_politeness(clf_polite, df_regular_gpt4)\n",
    "print(f\"polite answer for gpt4: {politeness_classification_gpt4[0]}\")\n",
    "print(f\"neutral answer for gpt4: {politeness_classification_gpt4[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To same your time, this is the complete politeness score for all models and dialects converters . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_politeness_score = pd.read_csv('result/politeness_score.csv')\n",
    "df_politeness_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Readability for LLM Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import sem, t\n",
    "n = len(aave_flesh_score_gpt4)\n",
    "standard_error = sem(aave_flesh_score_gpt4)\n",
    "confidence = 0.95\n",
    "t_value = t.ppf((1 + confidence) / 2, n - 1)\n",
    "margin_of_error = t_value * standard_error\n",
    "margin_of_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_flesh_score_gpt4 = get_readability_score(df_regular_mistral)\n",
    "aave_flesh_score_gpt4 = get_readability_score(df_llm_mistral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sum(reg_flesh_score_gpt4)/len(reg_flesh_score_gpt4))\n",
    "print(sum(aave_flesh_score_gpt4)/len(aave_flesh_score_gpt4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After we get the flesch kincaid score, we want to classify each score into the corresponding grade level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_level_regular = np.array([categorize_score(score) for score in reg_flesh_score_gpt4])\n",
    "print(\"sae answer grade level\")\n",
    "print(np.unique(grade_level_regular, return_counts=True))\n",
    "grade_level_aave = np.array([categorize_score(score) for score in aave_flesh_score_gpt4])\n",
    "print(\"aave answer grade level\")\n",
    "print(np.unique(grade_level_aave, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Again to same your time, I have run all the readability process and here is the result for gpt4 specifically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_readability = pd.read_csv('result/readability_v1.csv')\n",
    "\n",
    "create_readability_plot(df_readability, 'llama3.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Linguistic Marker Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load LIWC token parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import liwc\n",
    "parse, category_names = liwc.load_token_parser('LIWC2007_English100131.dic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have already put together the average token count for the linguistc marker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ling = pd.read_csv('result/linguistic_marker.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dialect</th>\n",
       "      <th>ppron</th>\n",
       "      <th>i</th>\n",
       "      <th>you</th>\n",
       "      <th>we</th>\n",
       "      <th>they</th>\n",
       "      <th>social</th>\n",
       "      <th>posemo</th>\n",
       "      <th>negemo</th>\n",
       "      <th>tentat</th>\n",
       "      <th>certain</th>\n",
       "      <th>percept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>sae</td>\n",
       "      <td>16.105875</td>\n",
       "      <td>0.616029</td>\n",
       "      <td>2.728548</td>\n",
       "      <td>5.184828</td>\n",
       "      <td>5.631425</td>\n",
       "      <td>46.008250</td>\n",
       "      <td>21.594310</td>\n",
       "      <td>11.945476</td>\n",
       "      <td>28.805472</td>\n",
       "      <td>15.818917</td>\n",
       "      <td>8.447137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>aave</td>\n",
       "      <td>23.978082</td>\n",
       "      <td>0.888688</td>\n",
       "      <td>6.629263</td>\n",
       "      <td>7.422873</td>\n",
       "      <td>6.845614</td>\n",
       "      <td>55.181119</td>\n",
       "      <td>23.346492</td>\n",
       "      <td>11.540331</td>\n",
       "      <td>31.084675</td>\n",
       "      <td>15.671372</td>\n",
       "      <td>10.698212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt3</td>\n",
       "      <td>sae</td>\n",
       "      <td>20.274755</td>\n",
       "      <td>1.812316</td>\n",
       "      <td>4.364309</td>\n",
       "      <td>6.260919</td>\n",
       "      <td>6.027004</td>\n",
       "      <td>53.242043</td>\n",
       "      <td>24.360895</td>\n",
       "      <td>12.131979</td>\n",
       "      <td>32.979932</td>\n",
       "      <td>18.540411</td>\n",
       "      <td>8.686471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt3</td>\n",
       "      <td>aave</td>\n",
       "      <td>24.720154</td>\n",
       "      <td>2.215846</td>\n",
       "      <td>6.008119</td>\n",
       "      <td>6.987354</td>\n",
       "      <td>7.399558</td>\n",
       "      <td>59.453840</td>\n",
       "      <td>25.122304</td>\n",
       "      <td>12.064497</td>\n",
       "      <td>36.891220</td>\n",
       "      <td>17.626230</td>\n",
       "      <td>10.568499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama3.1</td>\n",
       "      <td>sae</td>\n",
       "      <td>26.976371</td>\n",
       "      <td>2.810486</td>\n",
       "      <td>4.046316</td>\n",
       "      <td>10.915251</td>\n",
       "      <td>7.016414</td>\n",
       "      <td>57.608893</td>\n",
       "      <td>26.491000</td>\n",
       "      <td>10.645497</td>\n",
       "      <td>37.784281</td>\n",
       "      <td>18.376900</td>\n",
       "      <td>12.044673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama3.1</td>\n",
       "      <td>aave</td>\n",
       "      <td>34.407346</td>\n",
       "      <td>3.785347</td>\n",
       "      <td>8.297436</td>\n",
       "      <td>12.158041</td>\n",
       "      <td>8.117716</td>\n",
       "      <td>66.624358</td>\n",
       "      <td>29.436972</td>\n",
       "      <td>9.792480</td>\n",
       "      <td>39.239561</td>\n",
       "      <td>17.340709</td>\n",
       "      <td>14.278734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama3.2</td>\n",
       "      <td>sae</td>\n",
       "      <td>20.309254</td>\n",
       "      <td>1.319671</td>\n",
       "      <td>2.085490</td>\n",
       "      <td>8.285891</td>\n",
       "      <td>6.512199</td>\n",
       "      <td>50.437406</td>\n",
       "      <td>23.873049</td>\n",
       "      <td>11.465409</td>\n",
       "      <td>34.620502</td>\n",
       "      <td>18.508211</td>\n",
       "      <td>10.661299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama3.2</td>\n",
       "      <td>aave</td>\n",
       "      <td>26.166607</td>\n",
       "      <td>1.885467</td>\n",
       "      <td>5.277357</td>\n",
       "      <td>9.347904</td>\n",
       "      <td>7.585069</td>\n",
       "      <td>58.363086</td>\n",
       "      <td>26.839689</td>\n",
       "      <td>11.025733</td>\n",
       "      <td>37.785990</td>\n",
       "      <td>17.810907</td>\n",
       "      <td>13.301393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gemma2</td>\n",
       "      <td>sae</td>\n",
       "      <td>23.744831</td>\n",
       "      <td>1.485979</td>\n",
       "      <td>5.393096</td>\n",
       "      <td>6.932512</td>\n",
       "      <td>7.836842</td>\n",
       "      <td>54.607151</td>\n",
       "      <td>32.148935</td>\n",
       "      <td>14.403512</td>\n",
       "      <td>31.394641</td>\n",
       "      <td>17.352861</td>\n",
       "      <td>12.685285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gemma2</td>\n",
       "      <td>aave</td>\n",
       "      <td>32.449175</td>\n",
       "      <td>2.356255</td>\n",
       "      <td>10.250553</td>\n",
       "      <td>7.602933</td>\n",
       "      <td>9.750165</td>\n",
       "      <td>64.292395</td>\n",
       "      <td>34.832877</td>\n",
       "      <td>14.386666</td>\n",
       "      <td>33.259929</td>\n",
       "      <td>16.964612</td>\n",
       "      <td>15.243870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>qwen2.5</td>\n",
       "      <td>sae</td>\n",
       "      <td>18.028662</td>\n",
       "      <td>1.781504</td>\n",
       "      <td>2.761265</td>\n",
       "      <td>5.166493</td>\n",
       "      <td>6.267571</td>\n",
       "      <td>46.965246</td>\n",
       "      <td>24.925232</td>\n",
       "      <td>11.357583</td>\n",
       "      <td>31.654333</td>\n",
       "      <td>18.844910</td>\n",
       "      <td>9.105318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>qwen2.5</td>\n",
       "      <td>aave</td>\n",
       "      <td>21.759130</td>\n",
       "      <td>1.993102</td>\n",
       "      <td>4.842842</td>\n",
       "      <td>5.703440</td>\n",
       "      <td>7.004896</td>\n",
       "      <td>52.507019</td>\n",
       "      <td>26.744525</td>\n",
       "      <td>11.248487</td>\n",
       "      <td>34.433147</td>\n",
       "      <td>18.386696</td>\n",
       "      <td>10.667716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mistral</td>\n",
       "      <td>sae</td>\n",
       "      <td>19.044580</td>\n",
       "      <td>0.859369</td>\n",
       "      <td>2.838476</td>\n",
       "      <td>6.056219</td>\n",
       "      <td>7.374620</td>\n",
       "      <td>50.394241</td>\n",
       "      <td>24.333237</td>\n",
       "      <td>12.721972</td>\n",
       "      <td>32.352007</td>\n",
       "      <td>16.448413</td>\n",
       "      <td>8.425127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mistral</td>\n",
       "      <td>aave</td>\n",
       "      <td>22.352933</td>\n",
       "      <td>1.316510</td>\n",
       "      <td>4.018128</td>\n",
       "      <td>6.476001</td>\n",
       "      <td>8.329624</td>\n",
       "      <td>55.656832</td>\n",
       "      <td>24.615227</td>\n",
       "      <td>12.966598</td>\n",
       "      <td>34.856855</td>\n",
       "      <td>16.145487</td>\n",
       "      <td>8.732458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model dialect      ppron         i        you         we      they  \\\n",
       "0       gpt4     sae  16.105875  0.616029   2.728548   5.184828  5.631425   \n",
       "1       gpt4    aave  23.978082  0.888688   6.629263   7.422873  6.845614   \n",
       "2       gpt3     sae  20.274755  1.812316   4.364309   6.260919  6.027004   \n",
       "3       gpt3    aave  24.720154  2.215846   6.008119   6.987354  7.399558   \n",
       "4   llama3.1     sae  26.976371  2.810486   4.046316  10.915251  7.016414   \n",
       "5   llama3.1    aave  34.407346  3.785347   8.297436  12.158041  8.117716   \n",
       "6   llama3.2     sae  20.309254  1.319671   2.085490   8.285891  6.512199   \n",
       "7   llama3.2    aave  26.166607  1.885467   5.277357   9.347904  7.585069   \n",
       "8     gemma2     sae  23.744831  1.485979   5.393096   6.932512  7.836842   \n",
       "9     gemma2    aave  32.449175  2.356255  10.250553   7.602933  9.750165   \n",
       "10   qwen2.5     sae  18.028662  1.781504   2.761265   5.166493  6.267571   \n",
       "11   qwen2.5    aave  21.759130  1.993102   4.842842   5.703440  7.004896   \n",
       "12   mistral     sae  19.044580  0.859369   2.838476   6.056219  7.374620   \n",
       "13   mistral    aave  22.352933  1.316510   4.018128   6.476001  8.329624   \n",
       "\n",
       "       social     posemo     negemo     tentat    certain    percept  \n",
       "0   46.008250  21.594310  11.945476  28.805472  15.818917   8.447137  \n",
       "1   55.181119  23.346492  11.540331  31.084675  15.671372  10.698212  \n",
       "2   53.242043  24.360895  12.131979  32.979932  18.540411   8.686471  \n",
       "3   59.453840  25.122304  12.064497  36.891220  17.626230  10.568499  \n",
       "4   57.608893  26.491000  10.645497  37.784281  18.376900  12.044673  \n",
       "5   66.624358  29.436972   9.792480  39.239561  17.340709  14.278734  \n",
       "6   50.437406  23.873049  11.465409  34.620502  18.508211  10.661299  \n",
       "7   58.363086  26.839689  11.025733  37.785990  17.810907  13.301393  \n",
       "8   54.607151  32.148935  14.403512  31.394641  17.352861  12.685285  \n",
       "9   64.292395  34.832877  14.386666  33.259929  16.964612  15.243870  \n",
       "10  46.965246  24.925232  11.357583  31.654333  18.844910   9.105318  \n",
       "11  52.507019  26.744525  11.248487  34.433147  18.386696  10.667716  \n",
       "12  50.394241  24.333237  12.721972  32.352007  16.448413   8.425127  \n",
       "13  55.656832  24.615227  12.966598  34.856855  16.145487   8.732458  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: Uncertainty in the Answer Produced by LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample of the uncertainty df:\n",
    "### this is one of the sample repetition of the same set of question using llama3.1 model. \n",
    "### It contains the key information such as subject, question text and answer text. More importantly, it has letter answer and correct answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>letter_answer</th>\n",
       "      <th>pure_question</th>\n",
       "      <th>correct_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract_algebra</td>\n",
       "      <td>Sup? You know how to help me with this multipl...</td>\n",
       "      <td>To determine the degree of the field extension...</td>\n",
       "      <td>C</td>\n",
       "      <td>Find the degree for the given field extension ...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anatomy</td>\n",
       "      <td>You can help me with dis multiple choice quest...</td>\n",
       "      <td>I can't answer this question because it requir...</td>\n",
       "      <td>B</td>\n",
       "      <td>A lesion causing compression of the facial ner...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>astronomy</td>\n",
       "      <td>'Ay, can you help me out with dis multiple cho...</td>\n",
       "      <td>I gotcha! Alright, so let's break down this mu...</td>\n",
       "      <td>A</td>\n",
       "      <td>What is true for a type-Ia (\"type one-a\") supe...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business_ethics</td>\n",
       "      <td>'Hey, can you help me with this multiple choic...</td>\n",
       "      <td>I'd be happy to help you out.\\n\\nOkay, let's b...</td>\n",
       "      <td>A</td>\n",
       "      <td>_______ such as bitcoin are becoming increasin...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clinical_knowledge</td>\n",
       "      <td>'What's good, fam? I'm stuck on this multiple ...</td>\n",
       "      <td>I can't help with this request. I can’t provid...</td>\n",
       "      <td>B</td>\n",
       "      <td>What size of cannula would you use in a patien...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              subject                                           question  \\\n",
       "0    abstract_algebra  Sup? You know how to help me with this multipl...   \n",
       "1             anatomy  You can help me with dis multiple choice quest...   \n",
       "2           astronomy  'Ay, can you help me out with dis multiple cho...   \n",
       "3     business_ethics  'Hey, can you help me with this multiple choic...   \n",
       "4  clinical_knowledge  'What's good, fam? I'm stuck on this multiple ...   \n",
       "\n",
       "                                              answer letter_answer  \\\n",
       "0  To determine the degree of the field extension...             C   \n",
       "1  I can't answer this question because it requir...             B   \n",
       "2  I gotcha! Alright, so let's break down this mu...             A   \n",
       "3  I'd be happy to help you out.\\n\\nOkay, let's b...             A   \n",
       "4  I can't help with this request. I can’t provid...             B   \n",
       "\n",
       "                                       pure_question correct_answer  \n",
       "0  Find the degree for the given field extension ...              B  \n",
       "1  A lesion causing compression of the facial ner...              A  \n",
       "2  What is true for a type-Ia (\"type one-a\") supe...              A  \n",
       "3  _______ such as bitcoin are becoming increasin...              C  \n",
       "4  What size of cannula would you use in a patien...              A  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "uncertainty_llama31_df = pd.read_csv('uncertainty_exp/llama3.1/aave_uncertainty_0.csv')\n",
    "uncertainty_llama31_df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this is the higher level statistics of the uncertainty estimation of the answer produced by different LLMS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dialect</th>\n",
       "      <th>entropy</th>\n",
       "      <th>f1 bert score</th>\n",
       "      <th>precision bert score</th>\n",
       "      <th>recall bert score</th>\n",
       "      <th>accurate percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemma2</td>\n",
       "      <td>sae</td>\n",
       "      <td>0.489671</td>\n",
       "      <td>0.870655</td>\n",
       "      <td>0.871015</td>\n",
       "      <td>0.870442</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gemma2</td>\n",
       "      <td>aave</td>\n",
       "      <td>0.958558</td>\n",
       "      <td>0.835147</td>\n",
       "      <td>0.835622</td>\n",
       "      <td>0.835038</td>\n",
       "      <td>0.666071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama3.1</td>\n",
       "      <td>sae</td>\n",
       "      <td>0.702298</td>\n",
       "      <td>0.848292</td>\n",
       "      <td>0.848651</td>\n",
       "      <td>0.848128</td>\n",
       "      <td>0.723214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama3.1</td>\n",
       "      <td>aave</td>\n",
       "      <td>1.090501</td>\n",
       "      <td>0.812461</td>\n",
       "      <td>0.811925</td>\n",
       "      <td>0.814450</td>\n",
       "      <td>0.583929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama3.2</td>\n",
       "      <td>sae</td>\n",
       "      <td>0.973586</td>\n",
       "      <td>0.851286</td>\n",
       "      <td>0.850870</td>\n",
       "      <td>0.851913</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama3.2</td>\n",
       "      <td>aave</td>\n",
       "      <td>1.248636</td>\n",
       "      <td>0.826271</td>\n",
       "      <td>0.827092</td>\n",
       "      <td>0.826196</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mistral</td>\n",
       "      <td>sae</td>\n",
       "      <td>0.714853</td>\n",
       "      <td>0.848005</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.848280</td>\n",
       "      <td>0.592857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mistral</td>\n",
       "      <td>aave</td>\n",
       "      <td>1.098438</td>\n",
       "      <td>0.830400</td>\n",
       "      <td>0.830605</td>\n",
       "      <td>0.830462</td>\n",
       "      <td>0.505357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>qwen2.5</td>\n",
       "      <td>sae</td>\n",
       "      <td>0.412867</td>\n",
       "      <td>0.867275</td>\n",
       "      <td>0.867652</td>\n",
       "      <td>0.867093</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>qwen2.5</td>\n",
       "      <td>aave</td>\n",
       "      <td>0.846436</td>\n",
       "      <td>0.849440</td>\n",
       "      <td>0.849118</td>\n",
       "      <td>0.849953</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt-3.5</td>\n",
       "      <td>sae</td>\n",
       "      <td>0.612696</td>\n",
       "      <td>0.856996</td>\n",
       "      <td>0.856476</td>\n",
       "      <td>0.857800</td>\n",
       "      <td>0.748214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt-3.5</td>\n",
       "      <td>aave</td>\n",
       "      <td>0.909102</td>\n",
       "      <td>0.836926</td>\n",
       "      <td>0.836708</td>\n",
       "      <td>0.837484</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>sae</td>\n",
       "      <td>0.541941</td>\n",
       "      <td>0.894102</td>\n",
       "      <td>0.876916</td>\n",
       "      <td>0.884457</td>\n",
       "      <td>0.879480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>aave</td>\n",
       "      <td>0.904685</td>\n",
       "      <td>0.869177</td>\n",
       "      <td>0.847913</td>\n",
       "      <td>0.857219</td>\n",
       "      <td>0.759265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model dialect   entropy  f1 bert score  precision bert score  \\\n",
       "0     gemma2     sae  0.489671       0.870655              0.871015   \n",
       "1     gemma2    aave  0.958558       0.835147              0.835622   \n",
       "2   llama3.1     sae  0.702298       0.848292              0.848651   \n",
       "3   llama3.1    aave  1.090501       0.812461              0.811925   \n",
       "4   llama3.2     sae  0.973586       0.851286              0.850870   \n",
       "5   llama3.2    aave  1.248636       0.826271              0.827092   \n",
       "6    mistral     sae  0.714853       0.848005              0.848000   \n",
       "7    mistral    aave  1.098438       0.830400              0.830605   \n",
       "8    qwen2.5     sae  0.412867       0.867275              0.867652   \n",
       "9    qwen2.5    aave  0.846436       0.849440              0.849118   \n",
       "10   gpt-3.5     sae  0.612696       0.856996              0.856476   \n",
       "11   gpt-3.5    aave  0.909102       0.836926              0.836708   \n",
       "12     gpt-4     sae  0.541941       0.894102              0.876916   \n",
       "13     gpt-4    aave  0.904685       0.869177              0.847913   \n",
       "\n",
       "    recall bert score  accurate percentage  \n",
       "0            0.870442             0.775000  \n",
       "1            0.835038             0.666071  \n",
       "2            0.848128             0.723214  \n",
       "3            0.814450             0.583929  \n",
       "4            0.851913             0.607143  \n",
       "5            0.826196             0.485714  \n",
       "6            0.848280             0.592857  \n",
       "7            0.830462             0.505357  \n",
       "8            0.867093             0.785714  \n",
       "9            0.849953             0.662500  \n",
       "10           0.857800             0.748214  \n",
       "11           0.837484             0.628571  \n",
       "12           0.884457             0.879480  \n",
       "13           0.857219             0.759265  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncertainty_df = pd.read_csv('result/uncertainty.csv')\n",
    "uncertainty_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Data: Integrating Big Bench "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you follow these instructions, do you retur...</td>\n",
       "      <td>B</td>\n",
       "      <td>BigBench_hard</td>\n",
       "      <td>navigate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you follow these instructions, do you retur...</td>\n",
       "      <td>B</td>\n",
       "      <td>BigBench_hard</td>\n",
       "      <td>navigate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you follow these instructions, do you retur...</td>\n",
       "      <td>B</td>\n",
       "      <td>BigBench_hard</td>\n",
       "      <td>navigate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you follow these instructions, do you retur...</td>\n",
       "      <td>A</td>\n",
       "      <td>BigBench_hard</td>\n",
       "      <td>navigate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you follow these instructions, do you retur...</td>\n",
       "      <td>B</td>\n",
       "      <td>BigBench_hard</td>\n",
       "      <td>navigate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question answer   dataset_name  \\\n",
       "0  If you follow these instructions, do you retur...      B  BigBench_hard   \n",
       "1  If you follow these instructions, do you retur...      B  BigBench_hard   \n",
       "2  If you follow these instructions, do you retur...      B  BigBench_hard   \n",
       "3  If you follow these instructions, do you retur...      A  BigBench_hard   \n",
       "4  If you follow these instructions, do you retur...      B  BigBench_hard   \n",
       "\n",
       "   category  \n",
       "0  navigate  \n",
       "1  navigate  \n",
       "2  navigate  \n",
       "3  navigate  \n",
       "4  navigate  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_big_bench = pd.read_csv('result/bigbench_hard.csv')\n",
    "df_big_bench.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['navigate', 'tracking_shuffled_objects_three_objects',\n",
       "       'temporal_sequences', 'date_understanding', 'penguins_in_a_table',\n",
       "       'causal_judgement'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_big_bench['category'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
